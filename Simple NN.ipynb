{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.537959583787\n",
      "Accuracy: 46.2040416213\n",
      "\n",
      "[[ 0.70496194]\n",
      " [ 0.56062832]\n",
      " [ 0.72589074]\n",
      " [ 0.73339545]]\n",
      "Error: 0.00641417077263\n",
      "Accuracy: 99.3585829227\n",
      "\n",
      "[[ 0.01204072]\n",
      " [ 0.99949287]\n",
      " [ 0.98987622]\n",
      " [ 0.00298505]]\n",
      "Error: 0.00447526866281\n",
      "Accuracy: 99.5524731337\n",
      "\n",
      "[[ 0.00851149]\n",
      " [ 0.9997343 ]\n",
      " [ 0.99286485]\n",
      " [ 0.00198873]]\n",
      "Error: 0.00363014191512\n",
      "Accuracy: 99.6369858085\n",
      "\n",
      "[[ 0.00694903]\n",
      " [ 0.99981819]\n",
      " [ 0.99418329]\n",
      " [ 0.00157302]]\n",
      "Error: 0.00313070984731\n",
      "Accuracy: 99.6869290153\n",
      "\n",
      "[[ 0.00601796]\n",
      " [ 0.99986117]\n",
      " [ 0.99496747]\n",
      " [ 0.00133352]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid Function\n",
    "def nonlin(x, Deriv=False):\n",
    "    if(Deriv):\n",
    "        return x*(1-x)\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# Input Data Matrix\n",
    "X = np.array([[0,0,1], [1,1,0], [1,0,1], [0,1,1]])\n",
    "\n",
    "# Target Data Matrix --> To Predict\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Set Seed Value to reproduce results\n",
    "np.random.random(1)\n",
    "\n",
    "# Initialize Weights with random values\n",
    "weights_l0 = np.random.random((3,1))\n",
    "\n",
    "# Set Layer 0 as the Input data\n",
    "layer_0 = X\n",
    "\n",
    "# Set the Epochs\n",
    "epochs = 50000\n",
    "\n",
    "for iter in range(epochs):\n",
    "    \n",
    "    # Feed Forward through 2 Layers (Layer 0 being the I/P Layer)\n",
    "    layer_1 = nonlin(np.dot(layer_0, weights_l0))                   # Layer 1 --> Activation(Last_Layer(dot)Weights)\n",
    "    layer_1_error = y - layer_1                                     # Calculate Error - Prediction vs Actual Value\n",
    "    layer_1_delta = layer_1_error * nonlin(layer_1, True)           # Error Weighted Derivative --> Error * Deriv(Current_Layer)\n",
    "    \n",
    "    weights_l0 += np.dot(layer_0.T, layer_1_delta)                  # Update the Weight Vector\n",
    "    \n",
    "    if (iter % 10000) == 0:\n",
    "        print(\"Error: \"+str(np.mean(np.abs(layer_1_error))))        # layer_1_error contains the Error, take the absolute Values and calculate the mean\n",
    "        print(\"Accuracy: \"+str((1 - np.mean(np.abs(layer_1_error))) * 100))\n",
    "        print()\n",
    "        print(layer_1)                                              # These are the Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.161771457881\n",
      "Accuracy: 83.8228542119\n",
      "\n",
      "[[ 0.6796017 ]\n",
      " [ 0.73613833]\n",
      " [ 0.72636222]\n",
      " [ 0.71039858]]\n",
      "Error: 0.00966021166967\n",
      "Accuracy: 99.033978833\n",
      "\n",
      "[[ 0.00354159]\n",
      " [ 0.99683551]\n",
      " [ 0.99646821]\n",
      " [ 0.00314297]]\n",
      "Error: 0.00729816557787\n",
      "Accuracy: 99.2701834422\n",
      "\n",
      "[[ 0.00249795]\n",
      " [ 0.99769035]\n",
      " [ 0.99749783]\n",
      " [ 0.00228305]]\n",
      "Error: 0.00618318926823\n",
      "Accuracy: 99.3816810732\n",
      "\n",
      "[[ 0.00203862]\n",
      " [ 0.99808682]\n",
      " [ 0.99795556]\n",
      " [ 0.00188987]]\n",
      "Error: 0.00549237677727\n",
      "Accuracy: 99.4507623223\n",
      "\n",
      "[[ 0.00176536]\n",
      " [ 0.99832872]\n",
      " [ 0.9982289 ]\n",
      " [ 0.00165108]]\n"
     ]
    }
   ],
   "source": [
    "# Let's take the basic idea obtained above and build a deep(er) NN -- 2 Hidden Layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sigmoid Function\n",
    "def nonlin(x, Deriv=False):\n",
    "    if(Deriv):\n",
    "        return x*(1-x)\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# Input Data Matrix\n",
    "X = np.array([[0,0,1], [1,1,0], [1,0,1], [0,1,1]])\n",
    "\n",
    "# Target Data Matrix --> To Predict\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Set Seed Value to reproduce results\n",
    "np.random.random(1)\n",
    "\n",
    "# Initialize Weights with random values\n",
    "weights_l0 = np.random.random((3,4))\n",
    "weights_l1 = np.random.random((4,1))\n",
    "\n",
    "# Set Layer 0 as the Input data\n",
    "layer_0 = X\n",
    "\n",
    "# Set the Epochs\n",
    "epochs = 50000\n",
    "\n",
    "for iter in range(epochs):\n",
    "    # Feed Forward through 3 Layers (Layer 0 being the I/P Layer)\n",
    "    layer_1 = nonlin(np.dot(layer_0, weights_l0))                        # Layer 1 --> Activation(Last_Layer(dot)Weights)\n",
    "    layer_2 = nonlin(np.dot(layer_1, weights_l1))                        # Layer 2 --> Activation(Last_Layer(dot)Weights)\n",
    "    \n",
    "    layer_2_error = y - layer_2                                     # Calculate Error - Prediction vs Actual Value\n",
    "    layer_2_delta = layer_2_error * nonlin(layer_2, True)           # Error Weighted Derivative --> Error * Deriv(Current_Layer)\n",
    "    \n",
    "    layer_1_error = np.dot(layer_2_error, weights_l1.T)             # Layer 1 Error = Next Layer's Error (dot) Weights of Current Layer                     \n",
    "    layer_1_delta = layer_1_error * nonlin(layer_1, True)           # Error Weighted Derivative --> Error * Deriv(Current_Layer)\n",
    "    \n",
    "    weights_l1 += np.dot(layer_1.T, layer_2_delta)                  # Update the Weight Vectors\n",
    "    weights_l0 += np.dot(layer_0.T, layer_1_delta)\n",
    "    \n",
    "    if (iter % 10000) == 0:\n",
    "        print(\"Error: \"+str(np.mean(np.abs(layer_1_error))))        # layer_1_error contains the Error, take the absolute Values and calculate the mean\n",
    "        print(\"Accuracy: \"+str((1 - np.mean(np.abs(layer_1_error))) * 100))\n",
    "        print()\n",
    "        print(layer_2)                                              # These are the Predicted Values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
